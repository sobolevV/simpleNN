{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# determine XOR data\n",
    "data_in = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])    \n",
    "data_out = np.array([[0], [1], [1], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine functions\n",
    "\n",
    "# Activation function\n",
    "def sigmoid(layer):\n",
    "    return 1 / (1 + np.exp(-layer))\n",
    "\n",
    "# Deriv. sigmoid \n",
    "def sigmoid_diff(layer):\n",
    "    res_sigm = sigmoid(layer)\n",
    "    return res_sigm * (1 - res_sigm)\n",
    "\n",
    "def gradient(err, y_res):\n",
    "    gradient_layer = err*sigmoid_diff(y_res)\n",
    "    return gradient_layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Neural network (1 hidden layer)\n",
    "\n",
    "class NN():\n",
    "    def __init__(self, hidden_size, learning_rate):\n",
    "        # weights\n",
    "        self.w1 = np.random.rand(hidden_size, 2)\n",
    "        self.w2 = np.random.rand(1, hidden_size)\n",
    "        # biases\n",
    "        self.b1 = np.random.rand(hidden_size, 1)\n",
    "        self.b2 = np.random.rand(1, 1)\n",
    "        # learning rate\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        self.hidden = None\n",
    "        \n",
    "    def feedforward(self, X):\n",
    "        self.hidden = sigmoid(np.dot(self.w1, X.reshape(2, 1)) + nn.b1 ) # \n",
    "        out = sigmoid(np.dot(self.w2, self.hidden) + nn.b2)  #  \n",
    "        return out\n",
    "    \n",
    "    def backpropagation(self, target, out):\n",
    "        out = nn.feedforward(X)\n",
    "        # calc err\n",
    "        err = (Y - out.reshape(-1, 1))\n",
    "        # output layer gradient\n",
    "        gradient_output = -err*out*(1-out)\n",
    "\n",
    "        # weights delta\n",
    "        delta_w2 = np.dot(gradient_output, nn.hidden.T)\n",
    "        # update\n",
    "        nn.w2 -= (nn.lr) * delta_w2\n",
    "        # update biases\n",
    "        nn.b2 -= (nn.lr) * gradient_output\n",
    "\n",
    "        # hidden layer error\n",
    "        hidden_err = np.dot(nn.w2.T, err)\n",
    "        # hidden grad.\n",
    "        gradient_h = -hidden_err*nn.hidden * (1 - nn.hidden)\n",
    "\n",
    "        # weights delta\n",
    "        delta_w1 = np.dot(gradient_h, X.reshape(2, 1).T)\n",
    "        # update\n",
    "        nn.w1 -= (nn.lr)*delta_w1\n",
    "        # change biases\n",
    "        nn.b1 -= (nn.lr) * gradient_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 500, err 0.22985075601950447\n",
      "ep: 1000, err 0.23819747220778048\n",
      "ep: 1500, err 0.22854915770193512\n",
      "ep: 2000, err 0.2552355515620185\n",
      "ep: 2500, err 0.19225411055521865\n",
      "ep: 3000, err 0.2323299078759372\n",
      "ep: 3500, err 0.24793001447272475\n",
      "ep: 4000, err 0.20531719747071459\n",
      "ep: 4500, err 0.28710041710908313\n",
      "ep: 5000, err 0.1662160918202651\n",
      "ep: 5500, err 0.1632235545460709\n",
      "ep: 6000, err 0.1897448041957797\n",
      "ep: 6500, err 0.3689270015906819\n",
      "ep: 7000, err 0.1481847280572907\n",
      "ep: 7500, err 0.08289705276125446\n",
      "ep: 8000, err 0.037615865021358254\n",
      "ep: 8500, err 0.13469357823741918\n",
      "ep: 9000, err 0.0891934886110048\n",
      "ep: 9500, err 0.14066758670149798\n",
      "ep: 10000, err 0.03476989096657803\n",
      "ep: 10500, err 0.027145772194231338\n",
      "ep: 11000, err 0.029897174300105214\n",
      "ep: 11500, err 0.023037952398921962\n",
      "ep: 12000, err 0.020221648025807264\n",
      "ep: 12500, err 0.01480329319356497\n",
      "ep: 13000, err 0.011508102770594114\n",
      "ep: 13500, err 0.005242458257088189\n",
      "ep: 14000, err 0.0037884087815731344\n",
      "ep: 14500, err 0.006574691905523846\n",
      "ep: 15000, err 0.003177764577294368\n"
     ]
    }
   ],
   "source": [
    "nn = NN(5, 0.1)\n",
    "iterations = 15000\n",
    "\n",
    "for i in range(iterations):\n",
    "    \n",
    "    indx = np.random.randint(4)\n",
    "    X = data_in[indx]\n",
    "    Y = data_out[indx].reshape(1, 1)\n",
    "    \n",
    "    out = nn.feedforward(X)\n",
    "    err = Y - out\n",
    "    nn.backpropagation(Y, out)\n",
    "    \n",
    "    # nn.lr *= (1. / (1. + decay_rate * iterations))\n",
    "    if (i+1) % 500 == 0:\n",
    "        total_err = np.sum(err**2)/err.shape[0]\n",
    "        print(f\"ep: {i+1}, err {total_err}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "true_vals = 0\n",
    "tests = 500\n",
    "\n",
    "for i in range(tests):\n",
    "    indx = np.random.randint(4)\n",
    "    res = nn.feedforward(data_in[indx])\n",
    "    if (np.round(res[0])) == data_out[indx]:\n",
    "        true_vals += 1\n",
    "\n",
    "print(f\"accuracy: {(true_vals/tests) * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
